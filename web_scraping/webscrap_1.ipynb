{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0d24b1-3e4a-4c7f-8593-73480480977b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Basics — $29.99\n",
      "Learn Web Scraping — $24.99\n",
      "Data Science 101 — $34.50\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Open the local HTML file\n",
    "with open(r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html = file.read()\n",
    "\n",
    "# Step 2: Parse HTML\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Step 3: Find all books\n",
    "books = soup.find_all(\"div\", class_=\"book\")\n",
    "\n",
    "# Step 4: Extract title and price\n",
    "for book in books:\n",
    "    title = book.find(\"h2\", class_=\"title\").text\n",
    "    price = book.find(\"span\", class_=\"price\").text\n",
    "    print(f\"{title} — {price}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67e2f9fc-3b95-4219-8dc0-89a54b0f2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinity: ∞\n",
      "Pi: π\n",
      "Not equal: ≠\n",
      "Summation: ∑\n",
      "Subset: ⊂\n"
     ]
    }
   ],
   "source": [
    "print(\"Infinity: \\u221E\")\n",
    "print(\"Pi: \\u03C0\")\n",
    "print(\"Not equal: \\u2260\")\n",
    "print(\"Summation: \\u2211\")\n",
    "print(\"Subset: \\u2282\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfc603e-f073-4735-90ed-3e63203d7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Basics - price\n",
      "Learn Web Scraping - price\n",
      "Data Science 101 - price\n"
     ]
    }
   ],
   "source": [
    "# web scraping\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Open the local HTML file\n",
    "with open(\"books.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html = file.read()\n",
    "\n",
    "# Step 2: Parse HTML\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Step 3: Find all books\n",
    "books = soup.find_all(\"div\", class_=\"book\")\n",
    "\n",
    "# Step 4: Extract title and price\n",
    "for book in books:\n",
    "    title = book.find(\"h2\", class_=\"title\").text\n",
    "    price = book.find(\"span\", class_=\"price\").text\n",
    "    print(f\"{title} — {price}\")\n",
    "    '''\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book.html\", 'r', encoding = \"utf-8\") as file:\n",
    "    html = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "books = soup.find_all('div', class_ = 'book')\n",
    "\n",
    "for book in books:\n",
    "    title = book.find('h2', class_ = 'title').text\n",
    "    price = book.find('span', class_ = 'price').text\n",
    "    print(f\"{title} - {'price'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b87c5146-175a-4a8d-9337-3e0ee05ace29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is succesfully saved\n",
      "Hey man you extract the data from HTML and saved in excel succesfully\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "'''\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Step 1: Open the local HTML file\n",
    "with open(\"books2.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    html = file.read()\n",
    "\n",
    "# Step 2: Parse HTML\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Step 3: Find all books\n",
    "books = soup.find_all(\"div\", class_=\"book\")\n",
    "\n",
    "# Step 4: Extract all details\n",
    "for book in books:\n",
    "    title = book.find(\"h2\", class_=\"title\").text\n",
    "    price = book.find(\"span\", class_=\"price\").text\n",
    "    rating = book.find(\"span\", class_=\"rating\").text\n",
    "    buy_link = book.find(\"a\", class_=\"buy-link\")[\"href\"]\n",
    "\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Price: {price}\")\n",
    "    print(f\"Rating: {rating}\")\n",
    "    print(f\"Buy Link: {buy_link}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book2.html\",'r', encoding = 'utf-8') as file:\n",
    "    html = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "books = soup.find_all('div', class_ = 'book')\n",
    "\n",
    "\n",
    "book_data = []\n",
    "for book in books:\n",
    "    title = book.find('h2', class_ = 'title').text\n",
    "    price = book.find('span', class_ = 'price').text\n",
    "    rating = book.find('span', class_ = 'rating').text\n",
    "    buy_link = book.find('a', class_ = 'buy-link')['href']\n",
    "    book_data.append([title, price, rating, buy_link])\n",
    "\n",
    "# Step 5: Create DataFrame\n",
    "#df = pd.DataFrame(book_data, columns=[\"Title\", \"Price\", \"Rating\", \"Buy Link\"])\n",
    "df = pd.DataFrame(book_data, columns = ['title', 'price', 'rating', 'buy_link'])\n",
    "\n",
    "save_path = r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book2_Excel.xlsx\"\n",
    "df.to_excel(save_path, index = False, engine = \"openpyxl\")\n",
    "print('file is succesfully saved')\n",
    "print('Hey man you extract the data from HTML and saved in excel succesfully')\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf7955bf-7011-4488-a1a4-7118e5bead2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head><title>Books Page 1</title></head>\n",
      "<body>\n",
      "    <div class=\"book\">\n",
      "        <img src=\"https://example.com/images/python.jpg\" class=\"cover\">\n",
      "        <div class=\"info\">\n",
      "            <h2 class=\"title\">Learn Python</h2>\n",
      "            <div class=\"details\">\n",
      "                <span class=\"price\">$29.99</span>\n",
      "                <span class=\"rating\">★★★★☆</span>\n",
      "                <a href=\"https://buy.com/learn-python\" class=\"buy-link\">Buy Now</a>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"book\">\n",
      "        <img src=\"https://example.com/images/data.jpg\" class=\"cover\">\n",
      "        <div class=\"info\">\n",
      "            <h2 class=\"title\">Data Science Basics</h2>\n",
      "            <div class=\"details\">\n",
      "                <span class=\"price\">$34.50</span>\n",
      "                <span class=\"rating\">★★★★★</span>\n",
      "                <a href=\"https://buy.com/data-science\" class=\"buy-link\">Buy Now</a>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "<html>\n",
      "<head><title>Books Page 2</title></head>\n",
      "<body>\n",
      "    <div class=\"book\">\n",
      "        <img src=\"https://example.com/images/ml.jpg\" class=\"cover\">\n",
      "        <div class=\"info\">\n",
      "            <h2 class=\"title\">Machine Learning 101</h2>\n",
      "            <div class=\"details\">\n",
      "                <span class=\"price\">$42.00</span>\n",
      "                <span class=\"rating\">★★★★☆</span>\n",
      "                <a href=\"https://buy.com/ml-101\" class=\"buy-link\">Buy Now</a>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"book\">\n",
      "        <img src=\"https://example.com/images/stats.jpg\" class=\"cover\">\n",
      "        <div class=\"info\">\n",
      "            <h2 class=\"title\">Statistics for Beginners</h2>\n",
      "            <div class=\"details\">\n",
      "                <span class=\"price\">$27.80</span>\n",
      "                <span class=\"rating\">★★★☆☆</span>\n",
      "                <a href=\"https://buy.com/stats\" class=\"buy-link\">Buy Now</a>\n",
      "            </div>\n",
      "        </div>\n",
      "    </div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "File is saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "'''\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of local HTML files (simulate pagination)\n",
    "pages = [\"books_page1.html\", \"books_page2.html\"]\n",
    "\n",
    "# Store data from all pages\n",
    "all_books = []\n",
    "\n",
    "# Loop through each HTML file\n",
    "for page in pages:\n",
    "    with open(page, \"r\", encoding=\"utf-8\") as file:\n",
    "        html = file.read()\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    books = soup.find_all(\"div\", class_=\"book\")\n",
    "\n",
    "    for book in books:\n",
    "        image_url = book.find(\"img\", class_=\"cover\")[\"src\"]\n",
    "        title = book.find(\"h2\", class_=\"title\").text\n",
    "        price = book.find(\"span\", class_=\"price\").text\n",
    "        rating = book.find(\"span\", class_=\"rating\").text\n",
    "        buy_link = book.find(\"a\", class_=\"buy-link\")[\"href\"]\n",
    "\n",
    "        all_books.append([title, price, rating, image_url, buy_link])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_books, columns=[\"Title\", \"Price\", \"Rating\", \"Image URL\", \"Buy Link\"])\n",
    "\n",
    "# Save to Excel\n",
    "save_path = \"D:/DataProjects/WebScraping/books_paginated.xlsx\"  # Change path as needed\n",
    "df.to_excel(save_path, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"All paginated book data saved to Excel.\")\n",
    "\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pages = [r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book3a.html\", \n",
    "         r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book3b.html\"]\n",
    "all_books = []\n",
    "\n",
    "for page in pages:\n",
    "    with open(page, 'r', encoding = 'utf-8') as file:\n",
    "        html = file.read()\n",
    "    soup = BeautifulSoup(html, 'html.parser') \n",
    "    books = soup.find_all('div', class_ = 'book')\n",
    "    print(html)\n",
    "    \n",
    "    for book in books:\n",
    "        image_url = book.find('img', class_ = 'cover')['src']\n",
    "        title = book.find('h2', class_ = 'title').text\n",
    "        price = book.find('span', class_ = 'price').text\n",
    "        rating = book.find('span', class_ = 'rating').text\n",
    "        buy_link = book.find('a', class_ = 'buy-link')['href']\n",
    "        all_books.append([image_url, title, price, rating, buy_link])\n",
    "\n",
    "df = pd.DataFrame(all_books, columns = ['image_url', 'title', 'price', 'rating', 'buy_link'])\n",
    "\n",
    "save_path = r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book3_excel.xlsx\"\n",
    "\n",
    "try:\n",
    "    df.to_excel(save_path, index=False, engine='openpyxl')\n",
    "    print('File is saved successfully.')\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12ad67af-8708-4ef0-9ea4-a7916e1de960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does folder exist? True\n",
      "Expected save location: C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\book2_Excel.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Does folder exist?\", os.path.exists(os.path.dirname(save_path)))\n",
    "print(\"Expected save location:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a9de1c-64ed-4a40-82fb-2018f269316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "'''\n",
    "# Loop through first 3 pages\n",
    "for page_num in range(1, 4):  # Pages 1, 2, 3\n",
    "    url = f\"https://books.toscrape.com/catalogue/page-{page_num}.html\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    books = soup.find_all('article', class_='product_pod')\n",
    "    \n",
    "    for book in books:\n",
    "        # Title\n",
    "        title = book.h3.a['title']\n",
    "        # Price\n",
    "        price = book.find('p', class_='price_color').text\n",
    "        # Rating\n",
    "        rating = book.p['class'][1]  # Second class gives rating like 'Three', 'Five'\n",
    "        # Book link\n",
    "        book_link = \"https://books.toscrape.com/catalogue/\" + book.h3.a['href']\n",
    "        \n",
    "        all_books.append([title, price, rating, book_link])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_books, columns=['Title', 'Price', 'Rating', 'Book Link'])\n",
    "\n",
    "# Save to Excel\n",
    "save_path = r\"C:\\Users\\Sivaraman\\Desktop\\study\\data analytics\\project\\Data\\webscraping\\books_live.xlsx\"\n",
    "df.to_excel(save_path, index=False, engine='openpyxl')\n",
    "print(\"✅ Scraped data from real site saved successfully.\")\n",
    "'''\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "all_books = []\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
